{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Facial keypoints.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kos2001/coursera-aml-docker/blob/master/Facial_keypoints_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVQ43CVvSOXP",
        "colab_type": "text"
      },
      "source": [
        "## Facial keypoints detection\n",
        "\n",
        "In this task you will create facial keypoint detector based on CNN regressor.\n",
        "\n",
        "\n",
        "![title](example.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIsVRJDZSOXS",
        "colab_type": "text"
      },
      "source": [
        "### Load and preprocess data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-jqgN80SOXU",
        "colab_type": "text"
      },
      "source": [
        "Script `get_data.py` unpacks data — images and labelled points. 6000 images are located in `images` folder and keypoint coordinates are in `gt.csv` file. Run the cell below to unpack data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQLi0jJ5XsU7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrjIObrVXz-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from numpy import array, zeros\n",
        "from os.path import join\n",
        "from skimage.color import gray2rgb\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "import csv, cv2\n",
        "import os\n",
        "import skimage\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8z3y05PgmaE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%pwd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfzF_TKbxxf7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd drive/My Drive/FacialKeyPoints_week2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "si9kFsHOSOXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_size = 50\n",
        "num_imgs = 3000\n",
        "\n",
        "def load_imgs_and_keypoints(dirname='FacialKeyPoints_week2'):\n",
        "    # Write your code for loading images and points here\n",
        "    \n",
        "    points_dict={}\n",
        "    with open(\"./data/gt.csv\", 'r') as csvfile:\n",
        "        csvreader = csv.reader(csvfile)\n",
        "        count=0\n",
        "        for row in csvreader:\n",
        "            if count==0:\n",
        "                count+=1\n",
        "                continue\n",
        "            points_dict[row[0]]= [int(x) for x in row[1:]]\n",
        "    print(\"Dict created\")\n",
        "    \n",
        "    \n",
        "    folder = \"./data/images/\"\n",
        "    images = []\n",
        "    points = []\n",
        "    for filename in sorted(os.listdir(folder))[num_imgs:2*num_imgs]:\n",
        "        img = cv2.cvtColor(cv2.imread(os.path.join(folder,filename)), cv2.COLOR_BGR2RGB)\n",
        "        cols,rows,_ = img.shape\n",
        "        if img is not None:\n",
        "            images.append(skimage.transform.resize(img,(img_size,img_size)))\n",
        "            point = points_dict[filename]\n",
        "\n",
        "            for i in range(14):\n",
        "                point[2*i] = point[2*i]/cols - 0.5\n",
        "                point[2*i+1] = point[2*i+1]/rows - 0.5\n",
        "\n",
        "            points.append(point)\n",
        "      \n",
        "    images = np.array(images)\n",
        "    points = np.array(points)\n",
        "    print(images.shape,points.shape)\n",
        "    \n",
        "    return images, points\n",
        "\n",
        "imgs, points = load_imgs_and_keypoints()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3qn5H1wSOXe",
        "colab_type": "text"
      },
      "source": [
        "Now you have to read `gt.csv` file and images from `images` dir. File `gt.csv` contains header and ground truth points for every image in `images` folder. It has 29 columns. First column is a filename and next 28 columns are `x` and `y` coordinates for 14 facepoints. We will make following preprocessing:\n",
        "1. Scale all images to resolution $100 \\times 100$ pixels.\n",
        "2. Scale all coordinates to range $[-0.5; 0.5]$. To obtain that, divide all x's by width (or number of columns) of image, and divide all y's by height (or number of rows) of image and subtract 0.5 from all values.\n",
        "\n",
        "Function `load_imgs_and_keypoint` should return a tuple of two numpy arrays: `imgs` of shape `(N, 100, 100, 3)`, where `N` is the number of images and `points` of shape `(N, 28)`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x41Gblj7SOXh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Useful routines for preparing data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from os.path import join\n",
        "from skimage.color import gray2rgb\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "\n",
        "file = pd.read_csv('data/gt.csv')\n",
        "face_points = file[file.columns[1:]]\n",
        "\n",
        "def load_imgs_and_keypoints(dirname='data'):\n",
        "    # Write your code for loading images and points here\n",
        "    data = pd.read_csv(dirname + '/gt.csv')\n",
        "    N = data.shape[0]\n",
        "    points_arr = np.array(data[data.columns[1:]].values, dtype=np.float32)\n",
        "    points = np.zeros_like(points_arr, dtype=np.float32)\n",
        "    imgs = np.zeros((N, 100, 100, 3)) #fetching a size of 100 * 100 for image scaling\n",
        "    #scaling process\n",
        "    for i in range(N):\n",
        "        img = imread(dirname + '/images/' + data.filename[i])\n",
        "        w = img.shape[1]\n",
        "        h = img.shape[0]\n",
        "        points[i,:] = points_arr[i,:] / np.tile([w,h], 14) - 0.5\n",
        "        img = resize(img, (100,100, 3))\n",
        "        imgs[i,:,:,:] = img\n",
        "    \n",
        "    return imgs, points\n",
        "\n",
        "imgs, points = load_imgs_and_keypoints()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eJ1yz98SOXp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example of output\n",
        "%matplotlib inline\n",
        "from skimage.io import imshow\n",
        "imshow(imgs[0])\n",
        "points[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9uSbFgUSOXw",
        "colab_type": "text"
      },
      "source": [
        "### Visualize data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3f5O-41SOXx",
        "colab_type": "text"
      },
      "source": [
        "Let's prepare a function to visualize points on image. Such function obtains two arguments: an image and a vector of points' coordinates and draws points on image (just like first image in this notebook)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kawNJueuSOXz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Circle may be useful for drawing points on face\n",
        "# See matplotlib documentation for more info\n",
        "from matplotlib.patches import Circle\n",
        "\n",
        "def visualize_points(img, points):\n",
        "    # Write here function which obtains image and normalized\n",
        "    # coordinates and visualizes points on image\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    plt.imshow(img)\n",
        "    \n",
        "    points_int = np.clip(np.array((points+0.5)*100, dtype=np.int32), 0, 99) #points vector\n",
        "    \n",
        "    for i in range(14):\n",
        "        c = Circle((points_int[2*i], points_int[2*i+1]), radius=1, color='red')\n",
        "        ax.add_patch(c)\n",
        "    \n",
        "visualize_points(imgs[1], points[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVJfjTYqSOX3",
        "colab_type": "text"
      },
      "source": [
        "### Train/val split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQBCEcPmSOX5",
        "colab_type": "text"
      },
      "source": [
        "Run the following code to obtain train/validation split for training neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfzIjH_uSOX6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "imgs_train, imgs_val, points_train, points_val = train_test_split(imgs, points, test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDdIXD5PSOX_",
        "colab_type": "text"
      },
      "source": [
        "### Simple data augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyZvv-NoSOYA",
        "colab_type": "text"
      },
      "source": [
        "For better training we will use simple data augmentation — flipping an image and points. Implement function flip_img which flips an image and its' points. Make sure that points are flipped correctly! For instance, points on right eye now should be points on left eye (i.e. you have to mirror coordinates and swap corresponding points on the left and right sides of the face). VIsualize an example of original and flipped image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHzhHc4VSOYC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def flip_img(img, points):\n",
        "    # Write your code for flipping here\n",
        "    flip_image = img[:,::-1,:]\n",
        "    \n",
        "    flip_points = np.copy(points)\n",
        "    \n",
        "    for i in range(14):\n",
        "        flip_points[2*i] = -points[2*i]\n",
        "    return flip_image, flip_points\n",
        "\n",
        "f_img, f_points = flip_img(imgs[1], points[1])\n",
        "visualize_points(f_img, f_points)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnWW-8EESOYI",
        "colab_type": "text"
      },
      "source": [
        "Time to augment our training sample. Apply flip to every image in training sample. As a result you should obtain two arrays: `aug_imgs_train` and `aug_points_train` which contain original images and points along with flipped ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k74NprIUSOYJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Write your code here\n",
        "n = imgs_train.shape[0]\n",
        "\n",
        "aug_imgs_train = np.zeros((2*n, 100, 100, 3))\n",
        "aug_points_train = np.zeros((2*n, 28))\n",
        "\n",
        "for i in range(n):\n",
        "    aug_imgs_train[2*i] = imgs_train[i]\n",
        "    aug_points_train[2*i] = points_train[i]\n",
        "    \n",
        "    f_img, f_points = flip_img(imgs_train[i], points_train[i]) #flipping all 'count' number of images\n",
        "    \n",
        "    aug_imgs_train[2*i+1] = f_img\n",
        "    aug_points_train[2*i+1] = f_points"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVPAIpaJSOYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visualize_points(aug_imgs_train[2], aug_points_train[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UL__yJeSSOYT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visualize_points(aug_imgs_train[3], aug_points_train[3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNYvW2p7SOYY",
        "colab_type": "text"
      },
      "source": [
        "### Network architecture and training\n",
        "\n",
        "Now let's define neural network regressor. It will have 28 outputs, 2 numbers per point. The precise architecture is up to you. We recommend to add 2-3 (`Conv2D` + `MaxPooling2D`) pairs, then `Flatten` and 2-3 `Dense` layers. Don't forget about ReLU activations. We also recommend to add `Dropout` to every `Dense` layer (with p from 0.2 to 0.5) to prevent overfitting.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gi7NZINzSOYZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import (\n",
        "    Conv2D, MaxPooling2D, Flatten,\n",
        "    Dense, Dropout\n",
        ")\n",
        "\n",
        "model = Sequential()\n",
        "# Define here your model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsPz6K1USOYe",
        "colab_type": "text"
      },
      "source": [
        "Time to train! Since we are training a regressor, make sure that you use mean squared error (mse) as loss. Feel free to experiment with optimization method (SGD, Adam, etc.) and its' parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1_J-5BfxQur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import (\n",
        "    Conv2D, MaxPooling2D, Flatten,\n",
        "    Dense, Dropout\n",
        ")\n",
        "\n",
        "input_dim = aug_imgs_train[0].shape\n",
        "output_dim = aug_points_train.shape[1]\n",
        "\n",
        "model = Sequential()\n",
        "# Define here your model\n",
        "model.add(Conv2D(32, 3, activation='relu', input_shape=input_dim))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3), strides=None, padding=\"valid\"))\n",
        "model.add(Conv2D(64, 3, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3), strides=None, padding=\"valid\"))\n",
        "model.add(Conv2D(128, 3, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3), strides=None, padding=\"valid\"))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(output_dim, activation='linear'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAoXfx63xTpY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "\n",
        "# compile model\n",
        "model.compile(optimizer='Adam', loss=\"mse\", metrics=['mse'])\n",
        "print(model.summary())\n",
        "\n",
        "# fit model\n",
        "model.fit(aug_imgs_train, aug_points_train, batch_size=128, epochs=10, verbose=1)\n",
        "\n",
        "# Choose optimizer, compile model and run training"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlmWhStnxXWt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluate model\n",
        "model.evaluate(imgs_val, points_val, batch_size=32, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yl6hbV7QSOYm",
        "colab_type": "text"
      },
      "source": [
        "### Visualize results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UiMNhW7SOYn",
        "colab_type": "text"
      },
      "source": [
        "Now visualize neural network results on several images from validation sample. Make sure that your network outputs different points for images (i.e. it doesn't output some constant)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_TQzaqMSOYp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_points = model.predict(imgs, batch_size=32, verbose=1)\n",
        "i = 11\n",
        "visualize_points(imgs[i], pred_points[i])\n",
        "i = 13\n",
        "visualize_points(imgs[i], pred_points[i])\n",
        "i = 15\n",
        "visualize_points(imgs[i], pred_points[i])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}